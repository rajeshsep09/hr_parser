# Job Description Parsing Features

## ðŸŽ‰ Complete Job Description Support Added!

The HR Parser now supports both **Resume** and **Job Description** parsing with full canonical form storage in MongoDB.

## ðŸ“‹ New Features

### 1. **Job Description Schema** (`hr_parser/job_schemas.py`)
- **Company Information**: Name, industry, size, website, description
- **Job Details**: Title, department, employment type, work schedule, travel requirements, visa sponsorship
- **Location**: City, state, country, remote/hybrid options
- **Requirements**: Experience years, education level, required/preferred skills, certifications, languages
- **Compensation**: Salary range, currency, equity, benefits
- **Application**: Contact email, application URL, deadline, application method
- **Additional Fields**: Description, responsibilities, qualifications, benefits, culture, growth opportunities

### 2. **GPT-4o-mini Integration** (`hr_parser/job_gpt_client.py`)
- Uses OpenAI's GPT-4o-mini model for job description parsing
- Structured JSON output with validation
- Retry logic with exponential backoff (3 attempts)
- Mock mode support for testing
- Data cleaning and validation fixes

### 3. **MongoDB Storage** (`hr_parser/repository.py`)
- New `jobs_canonical` collection
- Deduplication by company name + job title (primary key)
- Fallback to company name, then hash
- Upsert functionality to prevent duplicates

### 4. **Service Layer** (`hr_parser/job_service.py`)
- `HRJobParserService` class for job parsing
- `parse_fileobj()` for single job descriptions
- `parse_bulk_fileobjs()` for multiple job descriptions
- Full schema validation with Pydantic

### 5. **API Endpoints** (`hr_parser/router.py`)
- `POST /hr/parser/job/single` - Parse single job description
- `POST /hr/parser/job/bulk` - Parse multiple job descriptions
- Consistent response format with resume endpoints

### 6. **Enhanced Web Interface** (`app/static/index.html`)
- **4 Upload Modes**:
  - Single Resume
  - Bulk Resumes
  - Single Job Description
  - Bulk Job Descriptions
- Dynamic UI updates based on selected mode
- Different icons and text for each mode
- Proper API endpoint routing

## ðŸ”§ Technical Details

### Schema Validation
- **Date Formats**: YYYY, YYYY-MM, or YYYY-MM-DD
- **Employment Types**: full_time, part_time, contract, internship, temporary
- **Education Levels**: high_school, associate, bachelor, master, phd, none
- **Country Codes**: 2-character ISO codes (US, GB, IN, etc.)
- **Email Validation**: Proper email format validation

### Deduplication Strategy
1. **Primary**: Company name + Job title combination
2. **Secondary**: Company name only
3. **Fallback**: SHA256 hash of content

### File Format Support
- PDF (with OCR fallback)
- DOCX
- DOC
- TXT
- RTF
- Images (PNG, JPG, JPEG, TIFF, BMP)

## ðŸ§ª Testing

### Test Files Created
- `test_job_functionality.py` - Comprehensive job parsing tests
- `test_job_mock.py` - Mock mode testing
- All tests include schema validation, API endpoints, and deduplication

### Test Results
- âœ… GPT parsing successful
- âœ… Schema validation working
- âœ… Mock mode functional
- âœ… Web interface updated
- âœ… API endpoints operational

## ðŸš€ Usage

### Web Interface
1. Open `http://localhost:8080/`
2. Select upload mode:
   - **Single Resume**: Upload one resume file
   - **Bulk Resumes**: Upload folder of resumes
   - **Single Job**: Upload one job description
   - **Bulk Jobs**: Upload folder of job descriptions
3. Drag & drop or click to browse
4. View results with confidence scores and IDs

### API Usage
```python
# Single job description
import requests
files = {"file": ("job.pdf", open("job.pdf", "rb"), "application/pdf")}
response = requests.post("http://localhost:8080/hr/parser/job/single", files=files)

# Bulk job descriptions
files = [("files", ("job1.pdf", open("job1.pdf", "rb"), "application/pdf")),
         ("files", ("job2.pdf", open("job2.pdf", "rb"), "application/pdf"))]
response = requests.post("http://localhost:8080/hr/parser/job/bulk", files=files)
```

### Programmatic Usage
```python
from hr_parser.job_service import HRJobParserService

service = HRJobParserService()
with open("job_description.pdf", "rb") as f:
    result = service.parse_fileobj(f, "job_description.pdf")
    print(f"Job ID: {result['job_id']}")
    print(f"Confidence: {result['parsing_confidence']}")
```

## ðŸ“Š Database Collections

### MongoDB Collections
- `resumes_canonical` - Parsed resume data
- `jobs_canonical` - Parsed job description data

### Sample Job Document Structure
```json
{
  "meta": {
    "canonical_version": "1.0",
    "parser_version": "hrx-0.1.0",
    "ingested_at": "2024-01-15T10:30:00Z",
    "source_file": "software_engineer_job.pdf",
    "parsing_confidence": 0.95
  },
  "company": {
    "name": "TechCorp",
    "industry": "Technology",
    "size": "201-1000"
  },
  "details": {
    "title": "Software Engineer",
    "employment_type": "full_time"
  },
  "location": {
    "city": "San Francisco",
    "state": "CA",
    "country": "US",
    "remote": true
  },
  "requirements": {
    "experience_years": 3,
    "education_level": "bachelor",
    "required_skills": ["Python", "JavaScript", "React"]
  },
  "compensation": {
    "salary_min": 90000,
    "salary_max": 120000,
    "currency": "USD",
    "equity": true
  },
  "dedupe": {
    "keys": ["company_title:techcorp_software_engineer"]
  }
}
```

## ðŸŽ¯ Next Steps

The HR Parser now provides complete support for both resumes and job descriptions with:
- âœ… Canonical form storage
- âœ… GPT-4o-mini parsing
- âœ… Deduplication
- âœ… Web interface
- âœ… API endpoints
- âœ… Comprehensive testing

Ready for production use! ðŸš€
